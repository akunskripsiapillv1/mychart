{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"/media/storage/alif/huggingface\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, LlavaForConditionalGeneration, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "import io\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# === Load ChartInstruct-LLaMA ===\n",
    "def load_chartinstruct_model(CHARTINSTRUCT_BASE, CHARTINSTRUCT_ADAPTER):\n",
    "    processor = AutoProcessor.from_pretrained(CHARTINSTRUCT_BASE)\n",
    "\n",
    "    quant_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    base_model = LlavaForConditionalGeneration.from_pretrained(\n",
    "        CHARTINSTRUCT_BASE,\n",
    "        torch_dtype=torch.float16,\n",
    "        quantization_config=quant_config,\n",
    "    )\n",
    "\n",
    "    model = PeftModel.from_pretrained(base_model, CHARTINSTRUCT_ADAPTER)\n",
    "    model.to(\"cuda\")\n",
    "    return model, processor\n",
    "\n",
    "# === Generate Descriptions ===\n",
    "def generate_chartinstruct(model, processor, image, prompt):\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(\"cuda\")\n",
    "    if \"pixel_values\" in inputs:\n",
    "        inputs[\"pixel_values\"] = inputs[\"pixel_values\"].to(torch.float16)\n",
    "\n",
    "    prompt_len = inputs[\"input_ids\"].shape[1]\n",
    "    outputs = model.generate(**inputs, max_new_tokens=256)\n",
    "    response = processor.decode(outputs[0][prompt_len:], skip_special_tokens=True).strip()\n",
    "    return prune_sentence(response)\n",
    "\n",
    "# ==== Compute Metrics ====\n",
    "def extract_numbers(text):\n",
    "    \"\"\"Ambil semua angka (integer dan desimal) dari teks sebagai list of float\"\"\"\n",
    "    numbers = re.findall(r'\\d+\\.?\\d*', text)\n",
    "    return list(map(float, numbers))\n",
    "\n",
    "def compute_relaxed_accuracy(gt_text, pred_text, tolerance=0.05):\n",
    "    \"\"\"Bandingkan angka-angka dari gt dan pred dengan toleransi error\"\"\"\n",
    "    gt_numbers = extract_numbers(gt_text)\n",
    "    pred_numbers = extract_numbers(pred_text)\n",
    "\n",
    "    # Handle case tidak ada angka sama sekali\n",
    "    if len(gt_numbers) == 0 and len(pred_numbers) == 0:\n",
    "        return 1.0  # Anggap benar jika tidak ada angka di keduanya\n",
    "    if len(gt_numbers) != len(pred_numbers):\n",
    "        return 0.0  # Jumlah angka berbeda â†’ salah\n",
    "\n",
    "    correct = 0\n",
    "    for gt, pred in zip(gt_numbers, pred_numbers):\n",
    "        denominator = max(gt, 1)  # Hindari division by zero\n",
    "        if abs(gt - pred) / denominator <= tolerance:\n",
    "            correct += 1\n",
    "\n",
    "    return correct / len(gt_numbers)\n",
    "\n",
    "def calculate_corpus_metrics(all_answers, all_preds):\n",
    "    \"\"\"Menghitung metrik tingkat korpus.\"\"\"\n",
    "    # Preprocessing teks\n",
    "    all_answers_lower = [a.lower().strip() for a in all_answers]\n",
    "    all_preds_lower = [p.lower().strip() for p in all_preds]\n",
    "    \n",
    "    bleu_score = 0.0\n",
    "    rouge_l_f = 0.0\n",
    "    cider_score = 0.0\n",
    "    \n",
    "    # Hitung BLEU\n",
    "    try:\n",
    "        bleu_score = corpus_bleu(\n",
    "            [[ref.split()] for ref in all_answers_lower],\n",
    "            [pred.split() for pred in all_preds_lower],\n",
    "            smoothing_function=SmoothingFunction().method4\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error BLEU: {str(e)}\")\n",
    "    \n",
    "    # Hitung ROUGE-L\n",
    "    try:\n",
    "        scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "        rouge_scores = [scorer.score(a, p)['rougeL'] for a, p in zip(all_answers, all_preds)]\n",
    "        rouge_l_f = sum([s.fmeasure for s in rouge_scores]) / len(rouge_scores)\n",
    "    except Exception as e:\n",
    "        print(f\"Error ROUGE: {str(e)}\")\n",
    "    \n",
    "    # Hitung CIDEr\n",
    "    try:\n",
    "        cider = Cider()\n",
    "        cider_score, _ = cider.compute_score(\n",
    "            {i: [a] for i, a in enumerate(all_answers_lower)},\n",
    "            {i: [p] for i, p in enumerate(all_preds_lower)}\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error CIDEr: {str(e)}\")\n",
    "    \n",
    "    return bleu_score, rouge_l_f, cider_score\n",
    "\n",
    "def prune_sentence(text):\n",
    "    \"\"\"\n",
    "    Mengambil kalimat utuh dari awal sampai titik terakhir.\n",
    "    Jika tidak ada titik, ambil sampai koma terakhir.\n",
    "    Jika tidak ada titik atau koma, ambil seluruh teks.\n",
    "    Hapus koma jika ada di akhir hasil.\n",
    "    \"\"\"\n",
    "    matches = list(re.finditer(r'\\.(?!\\d)', text))\n",
    "    if matches:\n",
    "        last_valid = matches[-1].start()\n",
    "        return text[:last_valid + 1].strip()\n",
    "    \n",
    "    last_comma = text.rfind(\",\")\n",
    "    if last_comma != -1:\n",
    "        return text[:last_comma].strip()\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def evaluate_model_with_metrics(dataset, model, processor, device=\"cuda\", output_file=\"predictions.csv\"):\n",
    "    results = []\n",
    "    all_answers = []\n",
    "    all_preds = []\n",
    "    total_numbers = 0\n",
    "    correct_numbers = 0\n",
    "\n",
    "    for idx in tqdm(range(len(dataset[\"test\"])), desc=\"Evaluasi Berjalan...\"):\n",
    "        sample = dataset[\"test\"][idx]\n",
    "\n",
    "        # Load gambar\n",
    "        image = Image.open(io.BytesIO(sample[\"image\"])).convert(\"RGB\")\n",
    "\n",
    "        # Buat prompt\n",
    "        prompt = f\"<image>\\nQuestion: {sample['query']} Answer:\"\n",
    "\n",
    "        # Generate jawaban\n",
    "        pred_text = generate_chartinstruct(model, processor, image, prompt)\n",
    "        \n",
    "        # Ground truth\n",
    "        ans_ref = sample[\"label\"]\n",
    "        ans_pred = pred_text\n",
    "\n",
    "        # Hitung relaxed accuracy\n",
    "        relaxed_acc = compute_relaxed_accuracy(ans_ref, ans_pred)\n",
    "\n",
    "        # Simpan hasil\n",
    "        results.append({\n",
    "            \"ID\": sample[\"imgname\"],\n",
    "            \"ans_ref\": ans_ref,\n",
    "            \"ans_pred\": ans_pred,\n",
    "            \"relaxed_accuracy\": relaxed_acc\n",
    "        })\n",
    "\n",
    "        all_answers.append(ans_ref)\n",
    "        all_preds.append(ans_pred)\n",
    "\n",
    "        # Statistik jumlah angka\n",
    "        gt_nums = extract_numbers(ans_ref)\n",
    "        pred_nums = extract_numbers(ans_pred)\n",
    "        total_numbers += len(gt_nums)\n",
    "        if len(gt_nums) == len(pred_nums):\n",
    "            correct_numbers += sum(1 for g,p in zip(gt_nums,pred_nums) if abs(g-p)/max(g,1) <= 0.05)\n",
    "\n",
    "    # Hitung metrik korpus\n",
    "    bleu_score, rouge_l_f, cider_score = calculate_corpus_metrics(all_answers, all_preds)\n",
    "\n",
    "    # Buat DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    df[\"BLEU\"] = bleu_score\n",
    "    df[\"ROUGE-L\"] = rouge_l_f\n",
    "    df[\"CIDEr\"] = cider_score\n",
    "\n",
    "    # Simpan ke CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nHasil evaluasi disimpan ke: {output_file}\")\n",
    "\n",
    "    # Print ringkasan\n",
    "    print(\"\\n=== Ringkasan Evaluasi ===\")\n",
    "    print(f\"Relaxed Accuracy (per sampel): {df['relaxed_accuracy'].mean():.4f}\")\n",
    "    if total_numbers > 0:\n",
    "        print(f\"Relaxed Accuracy (per angka): {correct_numbers / total_numbers:.4f}\")\n",
    "    print(f\"BLEU: {bleu_score:.4f}\")\n",
    "    print(f\"ROUGE-L: {rouge_l_f:.4f}\")\n",
    "    print(f\"CIDEr: {cider_score:.4f}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"akunskripsiapillv1/indochart-v2-dataset\")\n",
    "\n",
    "# Define model and adapter paths\n",
    "base_model_path = \"ahmed-masry/ChartInstruct-LLama2\"\n",
    "adapter_path = \"akunskripsiapillv1/finetuned-chartinstruct-llama-v2\"\n",
    "\n",
    "# Load model and processor\n",
    "model, processor = load_chartinstruct_model(base_model_path, adapter_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAMPEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sample_predictions(dataset_samples, model, processor, device=\"cuda\"):\n",
    "    results = []\n",
    "\n",
    "    for idx in range(len(dataset_samples)):\n",
    "        sample = dataset_samples[idx]\n",
    "\n",
    "        # Load gambar\n",
    "        image = Image.open(io.BytesIO(sample[\"image\"])).convert(\"RGB\")\n",
    "\n",
    "        # Buat prompt\n",
    "        prompt = f\"<image>\\nQuestion: {sample['query']} Answer:\"\n",
    "\n",
    "        # Generate jawaban\n",
    "        pred_text = generate_chartinstruct(model, processor, image, prompt)\n",
    "\n",
    "        # Simpan hasil\n",
    "        result = {\n",
    "            \"ID\": sample[\"imgname\"],\n",
    "            \"Query\": sample[\"query\"],\n",
    "            \"Ground Truth\": sample[\"label\"],\n",
    "            \"Prediction\": pred_text,\n",
    "        }\n",
    "\n",
    "        results.append(result)\n",
    "        print(f\"\\n--- Sample {idx+1} ---\")\n",
    "        print(f\"ID: {result['ID']}\")\n",
    "        print(f\"Query: {result['Query']}\")\n",
    "        print(f\"Ground Truth: {result['Ground Truth']}\")\n",
    "        print(f\"Prediction: {result['Prediction']}\\n\")\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding inputs for image tokens in LLaVa should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.50.\n",
      "Expanding inputs for image tokens in LLaVa should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.50.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample 1 ---\n",
      "ID: 27355.png\n",
      "Query: Buatkan deskripsi dari grafik berikut ini secara lengkap dan informatif\n",
      "Ground Truth: Statistik ini membandingkan jarak rata-rata yang ditempuh per orang setiap tahun untuk tujuan bisnis di Inggris pada tahun 2018, dengan moda transportasi. Perjalanan Surface Rail berada di posisi kedua, dengan rata-rata 120 mil yang ditempuh per orang per tahun untuk tujuan bisnis.\n",
      "Prediction: Statistik ini menunjukkan jangkauan tahunan rata-rata dari perangkat yang digunakan untuk tujuan bisnis di Inggris pada tahun 2018, dengan modus transportasi. Pada tahun 2018, jangkauan rata-rata perangkat yang digunakan untuk tujuan bisnis di Inggris adalah 375 mil per orang per tahun. Ini adalah jangkauan tertinggi untuk perangkat yang digunakan untuk tujuan bisnis di Inggris. Surface Rail adalah perangkat yang digunakan untuk tujuan bisnis dengan jangkauan rata-rata tertinggi kedua, dengan 120 mil per orang per tahun.\n",
      "\n",
      "\n",
      "--- Sample 2 ---\n",
      "ID: 17750.png\n",
      "Query: Buatkan deskripsi dari grafik berikut ini secara lengkap dan informatif\n",
      "Ground Truth: Statistik menunjukkan tingkat kebebasan internet di negara-negara Timur Tengah dan Afrika Utara tertentu. Menurut Indeks Freedom House, Suriah menduduki tempat terakhir dalam kebebasan internet dengan 86 poin indeks pada tahun 2019. Tunisia berada di peringkat pertama dengan 64 poin indeks.\n",
      "Prediction: Statistik ini menunjukkan negara-negara terkemuka di Timur Tengah dan Afrika Utara berdasarkan indeks poin indeks pengembangan pada tahun 2019. Pada tahun 2019, Tunisia berada di peringkat pertama dengan indeks poin indeks pengembangan 64. Pada tahun yang sama, Morocco berada di peringkat kedua dengan indeks 54. Lebanon berada di peringkat ketiga dengan indeks 52. Lebanon adalah negara dengan tingkat pertumbuhan tertinggi di wilayah ini. Pada tahun 2019, ekonomi Lebanon tumbuh sebesar 49 persen. Tunisia dan Morocco juga mengalami pertumbuhan yang signifikan dalam ekonomi mereka.\n",
      "\n",
      "\n",
      "--- Sample 3 ---\n",
      "ID: T0048_donut_a.png\n",
      "Query: Buatkan deskripsi dari grafik berikut ini secara lengkap dan informatif\n",
      "Ground Truth: Pada tahun 2021, Jumlah Pelanggan Sosial Perusahaan Daerah Air Minum (PDAM) di Kecamatan Kedungkandang sebanyak 595 orang, di Kecamatan Sukun sebanyak 559 orang, di Kecamatan Klojen sebanyak 527 orang, di Kecamatan Blimbing sebanyak 515 orang, dan di Kecamatan Lowokwaru sebanyak 537 orang. Dapat disimpulkan bahwa Kecamatan Kedungkandang memiliki angka tertinggi dalam hal jumlah pelanggan sosial Perusahaan Daerah Air Minum (PDAM) di Kota Malang, yaitu 595 orang, berbeda dengan Kecamatan Blimbing yang memiliki angka terendah, 515 orang.\n",
      "Prediction: Pada tahun 2021, terdapat 559 pelanggan sosial Perusahaan Daerah Air Minum (PDAM) di Kecamatan Kedungkandang, 527 di Kecamatan Sukun, 515 di Kecamatan Klojen, 537 di Kecamatan Blimbing, dan 595 di Kecamatan Lowokwaru. Kecamatan Kedungkandang tercatat sebagai wilayah dengan jumlah pelanggan sosial Perusahaan Daerah Air Minum (PDAM) terbanyak di Kota Malang, yakni mencapai 559 orang, sementara Kecamatan Klojen memiliki jumlah pelanggan sosial PDAM paling sedikit, yaitu 515 orang.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ambil 3 sampel pertama dari dataset test\n",
    "test_samples = dataset[\"test\"].select(range(3))\n",
    "\n",
    "# Jalankan evaluasi pada 3 sampel\n",
    "df_preview = evaluate_sample_predictions(test_samples, model, processor, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IndoChart Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3418ecc9a4d470cab3f24c3f008d522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluasi Berjalan...:   0%|          | 0/3678 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hasil evaluasi disimpan ke: eval_chartinstruct_results.csv\n",
      "\n",
      "=== Ringkasan Evaluasi ===\n",
      "Relaxed Accuracy (per sampel): 0.1941\n",
      "Relaxed Accuracy (per angka): 0.2479\n",
      "BLEU: 0.1849\n",
      "ROUGE-L: 0.4076\n",
      "CIDEr: 0.5713\n"
     ]
    }
   ],
   "source": [
    "# Jalankan evaluasi\n",
    "df_results = evaluate_model_with_metrics(\n",
    "    dataset=dataset,\n",
    "    model=model,\n",
    "    processor=processor,\n",
    "    output_file=\"eval_chartinstruct_results.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa44c9902d9b4f419f6f7c2ad8d4092d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b553b63de2246f7b6a3251b84ae279d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluasi Berjalan...:   0%|          | 0/1178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expanding inputs for image tokens in LLaVa should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.50.\n",
      "Expanding inputs for image tokens in LLaVa should be done in processing. Please add `patch_size` and `vision_feature_select_strategy` to the model's processing config or set directly with `processor.patch_size = {{patch_size}}` and processor.vision_feature_select_strategy = {{vision_feature_select_strategy}}`. Using processors without these attributes in the config is deprecated and will throw an error in v4.50.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hasil evaluasi disimpan ke: eval_chartinstruct_bps_results.csv\n",
      "\n",
      "=== Ringkasan Evaluasi ===\n",
      "Relaxed Accuracy (per sampel): 0.6156\n",
      "Relaxed Accuracy (per angka): 0.5876\n",
      "BLEU: 0.3750\n",
      "ROUGE-L: 0.6466\n",
      "CIDEr: 1.9627\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"akunskripsiapillv1/indochart-v2-dataset\")\n",
    "\n",
    "# Filter hanya data BPS untuk evaluasi\n",
    "def filter_bps(example):\n",
    "    return example[\"source\"] == \"bps\"\n",
    "\n",
    "# Terapkan filter hanya ke split 'test'\n",
    "test_bps = dataset[\"test\"].filter(filter_bps)\n",
    "\n",
    "# Define model and adapter paths\n",
    "base_model_path = \"ahmed-masry/ChartInstruct-LLama2\"\n",
    "adapter_path = \"akunskripsiapillv1/finetuned-chartinstruct-llama2-bps-v2\"\n",
    "\n",
    "# Load model dan processor\n",
    "model, processor = load_chartinstruct_model(base_model_path, adapter_path)\n",
    "\n",
    "# Jalankan evaluasi\n",
    "df_results = evaluate_model_with_metrics(\n",
    "    dataset={\"test\": test_bps},\n",
    "    model=model,\n",
    "    processor=processor,\n",
    "    output_file=\"eval_chartinstruct_bps_results.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statista Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2955b78263844340a530872d80e4e70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7cabe7a28e4151af8db3111d82cbf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11438bd9cfe4478daf1733a0685c52c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluasi Berjalan...:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hasil evaluasi disimpan ke: eval_chartinstruct_statista_results.csv\n",
      "\n",
      "=== Ringkasan Evaluasi ===\n",
      "Relaxed Accuracy (per sampel): 0.0466\n",
      "Relaxed Accuracy (per angka): 0.0475\n",
      "BLEU: 0.1218\n",
      "ROUGE-L: 0.3042\n",
      "CIDEr: 0.0392\n"
     ]
    }
   ],
   "source": [
    "# Filter hanya data Statista untuk evaluasi\n",
    "def filter_statista(example):\n",
    "    return example[\"source\"] == \"statista\"\n",
    "\n",
    "# Terapkan filter hanya ke split 'test'\n",
    "test_statista = dataset[\"test\"].filter(filter_statista)\n",
    "\n",
    "# Define model and adapter paths\n",
    "base_model_path = \"ahmed-masry/ChartInstruct-LLama2\"\n",
    "adapter_path = \"akunskripsiapillv1/finetuned-chartinstruct-llama2-statista-v2\"\n",
    "\n",
    "# Load model dan processor\n",
    "model, processor = load_chartinstruct_model(base_model_path, adapter_path)\n",
    "\n",
    "# Jalankan evaluasi\n",
    "df_results = evaluate_model_with_metrics(\n",
    "    dataset={\"test\": test_statista},\n",
    "    model=model,\n",
    "    processor=processor,\n",
    "    output_file=\"eval_chartinstruct_statista_results.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
